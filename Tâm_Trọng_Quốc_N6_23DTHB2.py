# k√≠nh ƒë·ªçc s√°ch - b·∫£n c·∫£i ti·∫øn s·ª≠a l·ªói OCR & h·∫≠u x·ª≠ l√Ω (Ti·∫øng Vi·ªát)
import cv2                            # X·ª≠ l√Ω ·∫£nh (OpenCV)
import pytesseract                    # Th∆∞ vi·ªán OCR nh·∫≠n d·∫°ng k√Ω t·ª± trong ·∫£nh
import nltk                           # X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (Natural Language Toolkit)
from gtts import gTTS                 # Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i (Google Text-to-Speech)
import os                             # Thao t√°c v·ªõi h·ªá th·ªëng t·ªáp
import numpy as np                    # X·ª≠ l√Ω m·∫£ng s·ªë li·ªáu, t√≠nh to√°n khoa h·ªçc
import re                             # X·ª≠ l√Ω bi·ªÉu th·ª©c ch√≠nh quy (regular expression)
from pyvi import ViTokenizer          # T√°ch t·ª´ ti·∫øng Vi·ªát
import unicodedata                    # Chu·∫©n h√≥a k√Ω t·ª± Unicode
from math import atan2, degrees       # H√†m to√°n h·ªçc: t√≠nh g√≥c v√† ƒë·ªïi sang ƒë·ªô

# n·∫øu c·∫ßn, t·∫£i punkt (d√πng cho fallback n·∫øu mu·ªën)
nltk.download('punkt', quiet=True)

# ƒë∆∞·ªùng d·∫´n tesseract (Windows)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# ------------------------------
# Ti·ªÅn x·ª≠ l√Ω ·∫£nh: resize, denoise, tƒÉng t∆∞∆°ng ph·∫£n, l√†m n√©t, deskew (t√πy ch·ªçn)
# ------------------------------
def preprocess_image_for_ocr(img, target_width=1600):
    # resize gi·ªØ t·ªâ l·ªá
    h, w = img.shape[:2]
    if w < target_width:
        scale = target_width / w
        img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)

    # chuy·ªÉn sang grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # lo·∫°i nhi·ªÖu nh∆∞ng gi·ªØ c·∫°nh: bilateralFilter t·ªët cho vƒÉn b·∫£n
    gray = cv2.bilateralFilter(gray, d=9, sigmaColor=75, sigmaSpace=75)

    # tƒÉng t∆∞∆°ng ph·∫£n nh·∫π (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    gray = clahe.apply(gray)

    # adaptive threshold ƒë·ªÉ t√°ch n·ªÅn ch·ªØ
    thresh = cv2.adaptiveThreshold(gray, 255,
                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY, 31, 9)

    # morphology: ƒë√≥ng ƒë·ªÉ n·ªëi n√©t b·ªã g√£y, r·ªìi m·ªü nh·∫π
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))
    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    processed = cv2.morphologyEx(processed, cv2.MORPH_OPEN, kernel)

    # (t√πy ch·ªçn) deskew: ∆∞·ªõc l∆∞·ª£ng g√≥c nghi√™ng v√† hi·ªáu ch·ªânh
    coords = np.column_stack(np.where(processed > 0))
    if coords.size:
        angle = cv2.minAreaRect(coords)[-1]
        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle
        if abs(angle) > 0.5:  # ch·ªâ quay n·∫øu nghi√™ng ƒë√°ng k·ªÉ
            (h2, w2) = processed.shape[:2]
            center = (w2 // 2, h2 // 2)
            M = cv2.getRotationMatrix2D(center, angle, 1.0)
            processed = cv2.warpAffine(processed, M, (w2, h2),
                                       flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

    # sharpen (khi c·∫ßn)
    kernel_sharp = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
    processed = cv2.filter2D(processed, -1, kernel_sharp)

    return processed

# ------------------------------
# M·ªü camera v√† ch·ª•p ·∫£nh (gi·ªØ g·∫ßn v·ªõi code g·ªëc)
# ------------------------------
def capture_text_images(max_pages=2):
    cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    if not cam.isOpened():
        print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c camera.")
        return []

    cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    captured_files = []
    print(f"üì∏ Nh·∫•n 'Space' ƒë·ªÉ ch·ª•p (t·ªëi ƒëa {max_pages} trang), 'Esc' ƒë·ªÉ tho√°t")

    while True:
        ret, frame = cam.read()
        if not ret:
            print("‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c khung h√¨nh")
            break

        preview = frame.copy()
        cv2.putText(preview, "Press SPACE to capture, ESC to exit", (10,30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)

        cv2.imshow("Camera - K√≠nh ƒë·ªçc s√°ch", preview)
        k = cv2.waitKey(1)

        if k % 256 == 27:  # ESC
            print("üëã Tho√°t camera!")
            break
        elif k % 256 == 32:  # SPACE
            img_name = f"captured_page_{len(captured_files)+1}.png"
            cv2.imwrite(img_name, frame)
            print(f"‚úÖ ƒê√£ l∆∞u ·∫£nh {img_name}")
            captured_files.append(img_name)

            if len(captured_files) >= max_pages:
                print("üìö ƒê√£ ch·ª•p ƒë·ªß s·ªë trang y√™u c·∫ßu.")
                break

    cam.release()
    cv2.destroyAllWindows()
    return captured_files

# ------------------------------
# OCR v·ªõi ti·ªÅn x·ª≠ l√Ω v√† c·∫•u h√¨nh Tesseract
# ------------------------------
def ocr_image_to_text(image_path):
    img = cv2.imread(image_path)
    if img is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh:", image_path)
        return ""

    processed = preprocess_image_for_ocr(img, target_width=1600)
    # d√πng psm 3 ho·∫∑c 6; n·∫øu t√†i li·ªáu l√† trang vƒÉn b·∫£n th√¨ 3 ho·∫∑c 6 ƒë·ªÅu OK
    custom_config = r'--oem 3 --psm 3'
    try:
        text = pytesseract.image_to_string(processed, lang="vie", config=custom_config)
    except Exception as e:
        print("‚ö†Ô∏è Tesseract (lang 'vie') l·ªói ho·∫∑c ch∆∞a c√†i: ", e)
        text = pytesseract.image_to_string(processed, config=custom_config)

    # h·∫≠u x·ª≠ l√Ω: chu·∫©n h√≥a unicode, lo·∫°i control chars, gi·ªØ l·∫°i ch·ªØ/s·ªë/d·∫•u c√¢u th√¥ng d·ª•ng
    text = unicodedata.normalize('NFC', text)

    # l·ªçc k√Ω t·ª±: ch·ªâ gi·ªØ ch·ªØ (Unicode category L), s·ªë (N) v√† m·ªôt s·ªë d·∫•u c√¢u ph·ªï bi·∫øn
    allowed_punct = set(". , : ; ! ? ( ) - ‚Äî \" ' % / \n".split())
    out_chars = []
    for ch in text:
        cat = unicodedata.category(ch)
        if cat.startswith('L') or cat.startswith('N') or ch.isspace() or ch in allowed_punct:
            out_chars.append(ch)
        # else: lo·∫°i b·ªè k√Ω t·ª± l·∫° (bi·ªÉu t∆∞·ª£ng, control, v.v.)
    cleaned = ''.join(out_chars)

    # thu g·ªçn kho·∫£ng tr·∫Øng + chu·∫©n h√≥a xu·ªëng d√≤ng: gi·ªØ m·ªôt xu·ªëng d√≤ng gi·ªØa ƒëo·∫°n
    cleaned = re.sub(r'[ \t]+', ' ', cleaned)
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned).strip()
    return cleaned

# ------------------------------
# Chu·∫©n h√≥a & token h√≥a ti·∫øng Vi·ªát (pyvi)
# - ViTokenizer tr·∫£ v·ªÅ t·ª´ n·ªëi b·∫±ng d·∫•u g·∫°ch d∆∞·ªõi: "Tr√≠_tu·ªá"
# - Tr∆∞·ªõc khi ƒë·ªçc b·∫±ng gTTS ta s·∫Ω bi·∫øn _ -> ' ' ƒë·ªÉ gi·ªçng ƒë·ªçc t·ª± nhi√™n
# ------------------------------
def correct_vietnamese_text(text):
    if not text.strip():
        return ""
    try:
        tokenized = ViTokenizer.tokenize(text)  # tr·∫£ v·ªÅ chu·ªói c√≥ d·∫•u g·∫°ch d∆∞·ªõi
    except Exception as e:
        print("‚ö†Ô∏è L·ªói ViTokenizer:", e)
        tokenized = text
    # gi·ªØ tokenized cho x·ª≠ l√Ω NLP nh∆∞ng tr·∫£ v·ªÅ c·∫£ phi√™n b·∫£n de-tokenized ƒë·ªÉ ƒë·ªçc
    detokenized = tokenized.replace('_', ' ')
    return tokenized, detokenized

# ------------------------------
# T√°ch c√¢u cho ti·∫øng Vi·ªát (regex ƒë∆°n gi·∫£n theo d·∫•u c√¢u)
# ------------------------------
def process_text_with_nlp_for_sentences(text):
    # t√°ch c√¢u theo .!? (gi·ªØ d·∫•u) ‚Äî ƒë∆°n gi·∫£n nh∆∞ng hi·ªáu qu·∫£ v·ªõi vƒÉn b·∫£n OCR
    pieces = re.split(r'(?<=[\.\?\!])\s+', text)
    # lo·∫°i c√°c c√¢u qu√° ng·∫Øn
    sentences = [p.strip() for p in pieces if len(p.strip()) > 0]
    return sentences

# ------------------------------
# Thu·∫≠t to√°n tham lam: ch·ªçn c√¢u theo S·ªê T·ª™ (words) ƒë·ªÉ gi·ªõi h·∫°n k√≠ch th∆∞·ªõc
# ------------------------------
def greedy_sentence_selection(sentences, max_words=100):
    # lo·∫°i c√¢u qu√° ng·∫Øn (v√≠ d·ª• <=2 t·ª´)
    clean_sentences = [s for s in sentences if len(s.split()) > 2]
    # s·∫Øp theo ƒë·ªô d√†i (s·ªë t·ª´) gi·∫£m d·∫ßn ‚Äî ∆∞u ti√™n c√¢u gi√†u n·ªôi dung
    sorted_sentences = sorted(clean_sentences, key=lambda s: len(s.split()), reverse=True)

    result = []
    total_words = 0
    for sent in sorted_sentences:
        wcount = len(sent.split())
        if total_words + wcount <= max_words:
            result.append(sent)
            total_words += wcount
    # tr·∫£ v·ªÅ theo th·ª© t·ª± xu·∫•t hi·ªán trong vƒÉn b·∫£n (ƒë·∫πp h∆°n khi ƒë·ªçc)
    result_in_order = [s for s in sentences if s in result]
    return result_in_order

# ------------------------------
# Text to Speech (gTTS) - d√πng detokenized text
# ------------------------------
def text_to_speech_vie(text, filename="output.mp3"):
    if not text.strip():
        print("‚ö†Ô∏è Kh√¥ng c√≥ vƒÉn b·∫£n ƒë·ªÉ ƒë·ªçc.")
        return
    try:
        tts = gTTS(text=text, lang="vi")
        tts.save(filename)
        print("üîä ƒê√£ t·∫°o file gi·ªçng ƒë·ªçc:", filename)
        # m·ªü file (Windows)
        if os.name == 'nt':
            os.system(f'start "" "{filename}"')
        else:
            os.system(f'xdg-open "{filename}"')
    except Exception as e:
        print("‚ö†Ô∏è L·ªói khi t·∫°o/kh·ªüi ch·∫°y gTTS:", e)

# ------------------------------
# MAIN
# ------------------------------
if __name__ == "__main__":
    img_paths = capture_text_images(max_pages=2)
    if img_paths:
        full_text = ""
        for img_path in img_paths:
            text = ocr_image_to_text(img_path)
            print(f"\nüìñ VƒÉn b·∫£n raw sau OCR ({img_path}):\n{text[:1000]}...\n")  # show 1k chars ƒë·ªÉ ki·ªÉm tra
            full_text += text + "\n"

        # token h√≥a v√† de-token h√≥a
        tokenized_all, detokenized_all = correct_vietnamese_text(full_text)
        # t√°ch c√¢u tr√™n b·∫£n detokenized (ƒë·ªÉ d·∫•u c√¢u t·ª± nhi√™n h∆°n)
        sentences = process_text_with_nlp_for_sentences(detokenized_all)

        selected_sentences = greedy_sentence_selection(sentences, max_words=120)
        final_text = " ".join(selected_sentences)

        print("ü§ñ VƒÉn b·∫£n s·∫Ω ƒë∆∞·ª£c ƒë·ªçc (preview):")
        print(final_text)
        text_to_speech_vie(final_text, filename="book_read.mp3")
    else:
        print("Kh√¥ng c√≥ ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.")
